<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="t-SNE,降维,流形学习,Manifold," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="说明  本文是用作2017-12-03晚晚茶会的试讲大纲。 由于晚茶会时间有限，本文目的是做成一个60分钟t-SNE闪电入门简介，可能无法详细讲解原理，学术帝请移步我的另一篇博文：论文笔记：Visualizing data using t-SNE  基础篇 认识高维空间：维数灾难  维数灾难（curse of dimensionality）描述的是高维空间中若干迥异于低维空间、甚至反直觉的现象。该">
<meta name="keywords" content="t-SNE,降维,流形学习,Manifold">
<meta property="og:type" content="article">
<meta property="og:title" content="t-SNE简介：A 60 Minute Blitz">
<meta property="og:url" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/index.html">
<meta property="og:site_name" content="胡东瑶的小屋">
<meta property="og:description" content="说明  本文是用作2017-12-03晚晚茶会的试讲大纲。 由于晚茶会时间有限，本文目的是做成一个60分钟t-SNE闪电入门简介，可能无法详细讲解原理，学术帝请移步我的另一篇博文：论文笔记：Visualizing data using t-SNE  基础篇 认识高维空间：维数灾难  维数灾难（curse of dimensionality）描述的是高维空间中若干迥异于低维空间、甚至反直觉的现象。该">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/high_dim_sparse_data.png">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/high_dim_marginal_data.png">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/curse_of_dimensionality.png">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/manifold_geodesic.png">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/sne_visualize.png">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Student_t_pdf.svg/325px-Student_t_pdf.svg.png">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/norm_vs_t_dist.png">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/t-sne_optimise.gif">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/sklearn_manifold.png">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/perp_1.png">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/perp_2.png">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/perp_3.png">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/perp_4.png">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/perp_5.png">
<meta property="og:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/perp_6.png">
<meta property="og:updated_time" content="2017-12-03T07:55:54.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="t-SNE简介：A 60 Minute Blitz">
<meta name="twitter:description" content="说明  本文是用作2017-12-03晚晚茶会的试讲大纲。 由于晚茶会时间有限，本文目的是做成一个60分钟t-SNE闪电入门简介，可能无法详细讲解原理，学术帝请移步我的另一篇博文：论文笔记：Visualizing data using t-SNE  基础篇 认识高维空间：维数灾难  维数灾难（curse of dimensionality）描述的是高维空间中若干迥异于低维空间、甚至反直觉的现象。该">
<meta name="twitter:image" content="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/high_dim_sparse_data.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/"/>





  <title>t-SNE简介：A 60 Minute Blitz | 胡东瑶的小屋</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">胡东瑶的小屋</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">You Can Advance!</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/12/01/t-sne-a-60-minutes-blitz/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dongyao Hu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="胡东瑶的小屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">t-SNE简介：A 60 Minute Blitz</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-12-01T10:00:37+08:00">
                2017-12-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2017/12/01/t-sne-a-60-minutes-blitz/" class="leancloud_visitors" data-flag-title="t-SNE简介：A 60 Minute Blitz">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="说明">说明</h2>
<ul>
<li>本文是用作2017-12-03晚晚茶会的试讲大纲。</li>
<li>由于晚茶会时间有限，本文目的是做成一个60分钟t-SNE闪电入门简介，可能无法详细讲解原理，学术帝请移步我的另一篇博文：<a href="https://psubnwell.github.io/2017/12/01/paper-note-t-sne/" target="_blank" rel="external">论文笔记：Visualizing data using t-SNE</a></li>
</ul>
<h2 id="基础篇">基础篇</h2>
<h3 id="认识高维空间维数灾难">认识高维空间：维数灾难</h3>
<ul>
<li><p><strong>维数灾难（curse of dimensionality）</strong>描述的是高维空间中<strong>若干迥异于低维空间、甚至反直觉</strong>的现象。该现象的详细论述可以参考文献<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>，其中通过超立方体和其内切球的推导十分精彩，这里不再赘述。</p>
<ul>
<li><p><strong>高维空间中数据样本极其稀疏。</strong>需要维度几何级数的数据才能满足在高维空间密采样（dense sample）。反过来，高维数据降维到低维空间也将发生“<strong>拥挤问题（Crowding Problem）</strong><a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>”</p>
<div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/high_dim_sparse_data.png">

</div></li>
<li><p><strong>高维单位空间中数据几乎全部位于超立方体的边缘。</strong></p>
<div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/high_dim_marginal_data.png">

</div>
<p>几何学能给出高维空间中超几何体的体积，单位超立方体的体积<span class="math inline">\(V_{hypercube} = 1^d = 1\)</span>，而其内切超球体的体积公式如下：</p>
<p><span class="math display">\[V_{hypersphere} = \frac{\pi^{\frac{n}{2}}}{\Gamma(\frac{n}{2} + 1)}\cdot 0.5^d\]</span></p>
<p>对两者商做极限<span class="math inline">\(\lim_{d \to +\infty}\frac{V_{hypersphere}}{V_{hypercube}}=0\)</span>，因此可以说一个高维单元空间只有边角，而没有中心。数据也只能处于边缘上，而远离中心。这样就直接导致了下一个性质：</p></li>
<li><p><strong>欧氏距离失效（因此任何基于欧氏距离的算法也失效）</strong>。</p>
<div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/curse_of_dimensionality.png">

</div>
<p>上图描述的是高维空间中大距离和小距离的差异越来越不明显。</p>
<p><span class="math display">\[\lim_{d\to +\infty}\frac{dist_{max} - dist_{min}}{d_{min}}=0\]</span></p>
<p>这是由上一性质自然推导出的结论。</p></li>
</ul></li>
</ul>
<h3 id="降维">降维</h3>
<ul>
<li><strong>降维（dimension reduction）</strong>的基本作用：
<ul>
<li>缓解维数灾难。即提高样本密度，以及使基于欧氏距离的算法重新生效。</li>
<li>数据预处理。对数据去冗余、降低信噪比。</li>
<li>方便可视化。</li>
</ul></li>
<li>降维的概念中有两对直觉性的概念会反复出现：高维/低维空间、高维/低维数据。在文献中他们有若干别称<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>：
<ul>
<li>高维空间（high-dimensional space），又叫原空间（original space）</li>
<li>高维数据（low-dimensional data），也直接叫<strong>数据点（data points）</strong>，用于和下述的<strong>映射点</strong>对应。</li>
<li>低维空间（low-dimensional space），又叫<strong>嵌入空间（embedded space）</strong>、<strong>低维映射（low-dimensional map</strong>，map在此做名词用）等</li>
<li>低维数据（low-dimensional data），又叫<strong>低维嵌入（low-dimensional embeddings）</strong>、<strong>低维表示（low-dimensional representations）</strong>、<strong>映射点（map points）</strong>等</li>
</ul></li>
<li><strong><a href="https://zh.wikipedia.org/wiki/%E5%B5%8C%E5%85%A5_(%E6%95%B0%E5%AD%A6)" target="_blank" rel="external">嵌入（embedding）</a></strong>：数学上，<strong>嵌入</strong>是指一个数学结构经映射<strong>包含在</strong>另一个结构中。
<ul>
<li>NLP目前所使用的<strong>词嵌入（word embedding）</strong>一词的本意可能就是这个意思。最初所使用的词向量是one-hot向量，维度等于词表大小（约几十万）。后来采用分布式表示的词向量，维度一般取几百维。因此我们认为分布式表示的词向量是更高维度语义空间的<strong>低维嵌入（embedding）</strong>。</li>
<li><strong>Embed Everything！</strong></li>
</ul></li>
<li>降维技术可以分为线性和非线性两大类：
<ul>
<li><strong>线性</strong>降维技术。侧重让<strong>不相似的点</strong>在低维表示中<strong>分开</strong>。
<ul>
<li>PCA（Principle Components Analysis，主成分分析）</li>
<li>MDS（Multiple Dimensional Scaling，多维缩放）等</li>
</ul></li>
<li><strong>非线性</strong>降维技术（<strong>广义上“非线性降维技术”≈“流形学习”</strong>，狭义上后者是前者子集）。这类技术假设高维数据实际上处于一个比所处空间维度低的非线性流形上，因此侧重让<strong>相似的近邻点</strong>在低维表示中<strong>靠近</strong>。
<ul>
<li>Sammon mapping</li>
<li><strong>SNE（Stochastic Neighbor Embedding，随机近邻嵌入）</strong>，<strong>t-SNE是基于SNE的</strong>。</li>
<li>Isomap（Isometric Mapping，等度量映射）</li>
<li>MVU（Maximum Variance Unfolding）</li>
<li>LLE（Locally Linear Embedding，局部线性嵌入）等</li>
</ul></li>
</ul></li>
</ul>
<h3 id="流形学习">流形学习</h3>
<div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/manifold_geodesic.png">

</div>
<ul>
<li>​</li>
<li><strong>流形（manifold）</strong>：
<ul>
<li><strong>机器学习</strong>中指的流形指<strong>本征维度较低</strong>但<strong>嵌入在高维空间</strong>中的<strong>空间</strong>（a manifold has <strong>low intrinsic dimensions</strong>, and is <strong>embedded</strong> within a space of much higher dimensionality<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>）。比如上图中的S-curve数据集，本征维度=2（摊开来是一个二维空间），但被嵌在三维空间中。</li>
<li><strong>数学</strong>中提到流形，强调其具有<strong>局部欧式空间</strong>的性质，可以在局部应用欧几里得距离。但是在机器学习（流形学习）中，这个假设基本不成立。原因是高维空间由于维数灾难的存在，没有足够稠密的数据能在足够小的局部去近似该流形<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>。</li>
<li>但是流形概念中<strong>局部</strong>的思想仍可以借鉴。它为降维提供了另一个视角：<strong>从微观角度去探索高维数据结构。</strong></li>
</ul></li>
<li>距离<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>：想象你是一只蚂蚁，在图中的二维曲面流形上行走。
<ul>
<li>高维直线距离：左图黑线。这个距离没有意义！</li>
<li>测地线距离：左图红线，右图红虚线。这个距离才有意义！</li>
<li>近邻距离：右图黑折线。用近邻距离可以拟合测地线距离。</li>
</ul></li>
<li>学习：流形学习之所以叫学习，因为它不像PCA一类的纯线性代数降维方法，而是更像一个类似神经网络的学习算法。
<ul>
<li>神经网络大部分是有监督学习；流形学习大部分是无监督学习。</li>
<li>神经网络拟合一个分类函数；流形学习（以t-SNE为例）拟合高维数据的分布。</li>
<li>神经网络学习参数；流形学习（以t-SNE为例）直接学习低维数据的表达。</li>
<li>两者均有损失函数、梯度下降、迭代轮数等学习算法的特点。</li>
</ul></li>
</ul>
<h2 id="学术篇">学术篇</h2>
<h3 id="sne">SNE</h3>
<ul>
<li><p>SNE（Stochastic Neighbor Embedding，随机近邻嵌入）<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p></li>
<li><p>SNE两个主要思路/步骤：</p>
<ul>
<li>将<strong>欧氏距离</strong>转化为<strong>条件概率</strong>来表征<strong>点间相似度（pairwise similarity）</strong>。</li>
<li>使用<strong>梯度下降</strong>算法来使低维分布学习/<strong>拟合</strong>高维分布。</li>
</ul></li>
<li><p>给定高维空间的数据点<span class="math inline">\(x_1, x_2, ..., x_n\)</span>，<span class="math inline">\(p_{i|j}\)</span>是<span class="math inline">\(x_i\)</span>以自己为中心，以高斯分布选择<span class="math inline">\(x_j\)</span>作为近邻点的条件概率。</p>
<p><span class="math display">\[p_{j|i} = \frac{exp(-||x_i-x_j||^2/2\sigma_i^2)}{\sum_{k\neq i}exp(-||x_i-x_k||^2/2\sigma_i^2)}\]</span></p>
<p>注意：1）对除i外其他所有j都计算一个条件概率后，形成一个概率分布列，所以分母需要归一化。2）默认<span class="math inline">\(p_{i|i}=0\)</span>。3）每不同数据点<span class="math inline">\(x_i\)</span>有不同的<span class="math inline">\(\sigma_i\)</span>，在此不展开。</p></li>
<li><p>同理，有低维空间的映射点<span class="math inline">\(y_1, y_2, …, y_n\)</span>（分别对应<span class="math inline">\(x_1, x_2, ..., x_n\)</span>），<span class="math inline">\(q_{j|i}\)</span>是<span class="math inline">\(y_i\)</span>以自己为中心，以高斯分布选择<span class="math inline">\(y_j\)</span>作为近邻点的条件概率。</p>
<p><span class="math display">\[q_{j|i} = \frac{exp(-||y_i-y_j||^2)}{\sum_{k\neq i}exp(-||y_i-y_k||^2)}\]</span></p>
<p>注意：这里方差统一取<span class="math inline">\(\sigma_i=1/\sqrt{2}\)</span>，若方差取其他值，对结果影响仅仅是缩放而已。</p></li>
<li><p>SNE的目标是让低维分布去拟合高维分布，则目标是令两个分布一致。<strong>两个分布的一致程度</strong>可以使用<strong>相对熵（Mutual entropy，也叫做KL散度，Kullback-Leibler divergences，KLD）</strong>来衡量，可以以此定义<strong>代价函数（cost function）</strong>：</p>
<p><span class="math display">\[C=\sum_i KL(P_i||Q_i) = \sum_i \sum_j p_{j|i} log\frac{p_{j|i}}{q_{j|i}}\]</span></p>
<p>其中 <span class="math inline">\(P_i(k=j)=p_{j|i}\)</span> 和 <span class="math inline">\(Q_i(k=j)=q_{j|i}\)</span> 是两个分布列。</p>
<p>注意：KLD是不对称的！因为 <span class="math inline">\(KLD=p log(\frac{p}{q})\)</span>，p&gt;q时为正，p&lt;q时为负。则如果<strong>高维数据相邻</strong>而<strong>低维数据分开</strong>（即p大q小），则<strong>cost很大</strong>；相反，如果<strong>高维数据分开</strong>而<strong>低维数据相邻</strong>（即p小q大），则<strong>cost很小</strong>。所以<strong>SNE倾向于保留高维数据的局部结构</strong>。</p></li>
<li><p>对<span class="math inline">\(C\)</span>进行梯度下降即可以学习到合适的<span class="math inline">\(y_i\)</span>。</p>
<p>梯度公式：</p>
<p><span class="math display">\[\frac{\partial C}{\partial y_i} = 2 \sum_j (p_{j|i} - q_{j|i} + p_{i|j} - q_{i|j})(y_i - y_j)\]</span></p>
<p>带动量的梯度更新公式：（这里给出单个<span class="math inline">\(y_i\)</span>点的梯度下降公式，显然需要对所有<span class="math inline">\(\mathcal{Y}^{(T)}=\{y_1, y_2, ..., y_n\}\)</span>进行统一迭代。）</p>
<p><span class="math display">\[y_i^{(t)} = y_i^{(t-1)} + \eta \frac{\partial C}{\partial y_i} + \alpha(t)( y_i^{(t-1)} - y_i^{(t-2)})\]</span></p></li>
</ul>
<h3 id="t-sne">t-SNE</h3>
<ul>
<li><p><strong>t-Distributed</strong> Stochastic Neighbor Embedding<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></p></li>
<li><p>事实上SNE并没有解决维度灾难带来的若干问题：</p>
<ul>
<li><p><strong>拥挤问题（Crowding Problem）</strong>：在二维映射空间中，能容纳<strong>（高维空间中的）中等距离间隔点</strong>的空间，不会比能容纳<strong>（高维空间中的）相近点</strong>的空间大太多。<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a></p></li>
<li><p>换言之，哪怕高维空间中离得较远的点，在低维空间中留不出这么多空间来映射。于是到最后高维空间中的点，尤其是远距离和中等距离的点，在低维空间中统统被塞在了一起，这就叫做“<strong>拥挤问题（Crowding Problem）</strong>”。</p></li>
<li><p>拥挤问题带来的一个直接后果，就是高维空间中分离的簇，在低维中被分的不明显（但是可以分成一个个区块）。比如用SNE去可视化MNIST数据集的结果如下：</p>
<div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/sne_visualize.png">

</div></li>
</ul></li>
<li><p>如何解决？高维空间保持高斯分布不变，将低维空间的分布做调整，使得两边尾巴比高维空间的高斯分布更高，即可缓解拥挤问题。想一想为什么？(在下面t-分布中解释)</p>
<ul>
<li><strong>UNI-SNE</strong><a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a>：给低维空间的点给予一个<strong>均匀分布（uniform dist）</strong>，使得<strong>对于高维空间中距离较远的点（<span class="math inline">\(p_{ij}\)</span>较小），强制保证在低维空间中<span class="math inline">\(q_{ij}&gt;p_{ij}\)</span></strong> （因为均匀分布的两边比高斯分布的两边高出太多了）。</li>
</ul></li>
<li><p><strong>t-分布（<a href="https://en.wikipedia.org/wiki/Student%27s_t-distribution" target="_blank" rel="external">Student’s t-distribution</a>）</strong></p>
<ul>
<li><p>t-分布的概率密度函数（probability density function，PDF）形式为：</p>
<p><span class="math display">\[f(t) = \frac{\Gamma(\frac{\nu + 1}{2})}{\sqrt{\nu \pi}\Gamma(\frac{\nu}{2})}(1 + \frac{t^2}{\nu})^{-\frac{\nu + 1}{2}}\]</span></p>
<p>其中 <span class="math inline">\(\nu\)</span> 是自由度。</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Student_t_pdf.svg/325px-Student_t_pdf.svg.png" alt="figure of probability density function">
<p class="caption">figure of probability density function</p>
</div></li>
<li><p>当 <span class="math inline">\(\nu = 1\)</span></p>
<p><span class="math display">\[f(t) =  \frac{1}{\pi (1+t^2)}\]</span></p>
<p>叫做<strong>柯西分布（Cauchy distribution）</strong>，我们用到是这个简单形式。</p></li>
<li><p>当 <span class="math inline">\(\nu = \infty\)</span></p>
<p><span class="math display">\[f(t) = \frac{1}{\sqrt{2\pi}} e^{-\frac{t^2}{2}}\]</span></p>
<p>叫做<strong>高斯/正态分布（Guassian/Normal distribution）</strong>。</p></li>
</ul></li>
<li><p>我们在低维空间的分布中，把原先用的高斯分布改成自由度为1的分布（把尾巴抬高）。下图可以很好地说明为什么“把尾巴抬高”可以很好地缓解拥挤问题。绘图代码参考<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a></p>
<div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/norm_vs_t_dist.png">

</div>
<p>假设我们的低维数据分布对高维数据分布已经拟合完毕，则可以认为对于高维数据点<span class="math inline">\(x_i\)</span>、<span class="math inline">\(x_j\)</span>和低维映射点<span class="math inline">\(y_i\)</span>、<span class="math inline">\(y_j\)</span>，有<span class="math inline">\(p_{ij}=q_{ij}\)</span>。我们用图中两条红线表示两种情况：</p>
<ul>
<li>上面的红线表示：当两个点相距<strong>相对近</strong>的时候，低维空间中比高维空间中<strong>相对更近</strong>。</li>
<li>下面的红线表示：当两个点相距<strong>相对远</strong>的时候，低维空间中比高维空间中<strong>相对更远</strong>。</li>
</ul></li>
<li><p>可以对比一下采用t-SNE对MNIST数据集的降维可视化效果</p>
<div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/t-sne_optimise.gif">

</div></li>
<li><p>以上是t-SNE的主要思想，其余还有若干知识点（如对称SNE、优化的技巧等），请参考论文<a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a>或者我的另一篇博文：<a href="https://psubnwell.github.io/2017/12/01/paper-note-t-sne/" target="_blank" rel="external">论文笔记：Visualizing data using t-SNE</a>。</p></li>
</ul>
<h2 id="工程篇">工程篇</h2>
<h3 id="python库sklearn.manifold">Python库：<code>sklearn.manifold</code></h3>
<ul>
<li><p>推荐阅读Python下著名的机器学习库scikit-learn的相应文档：<a href="http://scikit-learn.org/stable/modules/manifold.html#t-distributed-stochastic-neighbor-embedding-t-sne" target="_blank" rel="external"><code>sklearn.manifold.TSNE</code> - scikit-learn</a></p></li>
<li><div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/sklearn_manifold.png">

</div></li>
</ul>
<h3 id="困惑度">困惑度</h3>
<ul>
<li><p>使用t-SNE时，除了指定你想要降维的维度（参数<code>n_components</code>），另一个重要的参数是困惑度（Perplexity，参数<code>perplexity</code>）。</p></li>
<li><p>前面提到高维空间中每一个数据点<span class="math inline">\(x_i\)</span>的高斯分布中的方差<span class="math inline">\(\sigma_i\)</span>都必须设为不同。该方差<span class="math inline">\(\sigma_i\)</span>须具有如下性质：在数据密集的地方要小，数据稀疏的地方要大。</p></li>
<li><p>如何给每个<span class="math inline">\(x_i\)</span>分配<span class="math inline">\(\sigma_i\)</span>值呢？</p>
<ul>
<li>可以手动分配（逃，论文原话。。。<a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a></li>
<li>使用算法分配：Binary search<a href="#fn14" class="footnoteRef" id="fnref14"><sup>14</sup></a><a href="#fn15" class="footnoteRef" id="fnref15"><sup>15</sup></a> 或者 Root-finding method<a href="#fn16" class="footnoteRef" id="fnref16"><sup>16</sup></a></li>
</ul></li>
<li><p>使用算法来确定<span class="math inline">\(\sigma_i\)</span>则要求用户预设困惑度。然后算法找到合适的<span class="math inline">\(\sigma_i\)</span>值让条件分布<span class="math inline">\(P_i\)</span>的困惑度等于用户预定义的困惑度即可。</p>
<p><span class="math inline">\(Perp(P_i) = 2^{H(P_i)} = 2^{-\sum_j p_{j|i} log_2 p_{j|i}}\)</span></p>
<p>注意：困惑度设的大，则显然<span class="math inline">\(\sigma_i\)</span>也大。两者是单调关系，因此可以使用binary search<a href="#fn17" class="footnoteRef" id="fnref17"><sup>17</sup></a>。</p></li>
<li><p>论文<a href="#fn18" class="footnoteRef" id="fnref18"><sup>18</sup></a>建议<strong>困惑度设为5-50比较好</strong>。这还是一个很大的范围，事实上在这个范围内，<strong>调节困惑度可以展示从微观到宏观的一系列视角</strong>，见下一节。</p></li>
</ul>
<h3 id="可视化">可视化</h3>
<ul>
<li><p>日常使用t-SNE可调的参数基本只有困惑度，非常简单。针对困惑度如何影响可视化结果，文献<a href="#fn19" class="footnoteRef" id="fnref19"><sup>19</sup></a>做了非常详细的展示，还包含一个在线程序可以辅助认识。</p></li>
<li><p>文献<a href="#fn20" class="footnoteRef" id="fnref20"><sup>20</sup></a>给出的基本结论如下：</p>
<ul>
<li>簇（cluster）的大小无关紧要。</li>
<li>簇之间的距离无关紧要。</li>
<li>密集的区域会被扩大，稀疏的区域会被缩小。等</li>
</ul></li>
<li><p>根据文献<a href="#fn21" class="footnoteRef" id="fnref21"><sup>21</sup></a>给的图，说一点自己的理解：</p>
<div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/perp_1.png">

</div>
<div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/perp_2.png">

</div>
<div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/perp_3.png">

</div>
<div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/perp_4.png">

</div>
<div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/perp_5.png">

</div>
<div class="figure">
<img src="/2017/12/01/t-sne-a-60-minutes-blitz/perp_6.png">

</div>
<ul>
<li>低困惑度对应的是局部视角，要把自己想象成一只蚂蚁，在数据所在的流形上一个点一个点地探索。</li>
<li>高困惑度对应的是全局视角，要把自己想象成上帝。</li>
</ul></li>
</ul>
<h3 id="t-sne优点">t-SNE优点</h3>
<ul>
<li>流形学习中其他方法如Isomap、LLE等，主要用于<strong>展开单个连续的低维流形</strong>（比如“瑞士卷”数据集），而t-SNE主要用于数据的局部结构，并且会倾向于提取出局部的簇，<strong>这种能力对于可视化同时包含多个流形的高维数据（比如MNIST数据集）很有效</strong>。</li>
</ul>
<h3 id="t-sne缺点">t-SNE缺点</h3>
<ul>
<li>时间、空间复杂度为<span class="math inline">\(O(n^2)\)</span>，计算代价昂贵。百万量级的数据需要几小时，对于PCA可能只需要几分钟。</li>
<li>升级版Barnes-Hut t-SNE可以让复杂度降为<span class="math inline">\(O(nlogn)\)</span>，但只限于获得二维和三维的嵌入。（sklearn中可以直接使用参数<code>method=’barnes_hut’</code>）</li>
<li>由于代价函数非凸，多次执行算法的结果是随机的（名字中“Stochatsic”的由来？），需要多次运行选取最好的结果。</li>
<li>全局结构不能很清楚的保留。这个问题可以通过先用PCA降维到一个合理的维度（如50）后再用t-SNE来缓解，前置的PCA步骤也可以起到去除噪声等功能，。（sklearn中可以直接使用参数<code>init='pca'</code>）</li>
</ul>
<h2 id="尾声">尾声</h2>
<blockquote>
<p>这次褐蚁来到故地，只是觅食途中偶然路过而已。它来到孤峰脚下，用触须摸了摸这顶天立地的存在，发现孤峰的表面坚硬光滑，但能爬上去，于是它向上爬去。<strong>没有什么且的，只是那小小的简陋神经网络中的一次随机扰动所致。</strong>这扰动随处可见，在地面的每一株小草和草叶上的每一粒露珠中，在天空中的每一片云和云后的每一颗星辰上……<strong>扰动都是无目的的，但巨量的无目的扰动汇集在一起，目的就出现了。</strong>…</p>
<p>与此同时，在前方的峭壁上，<strong>它遇到了一道长长的沟槽</strong>，与峭壁表面相比，沟槽的凹面粗糙一些，颜色也不同，呈灰白色，它沿着沟槽爬，粗糙的表面使攀登容易了许多。沟槽的两端都有短小的细槽。下端的细槽与主槽垂直，上端的细槽则与主槽成一个角度相交。<strong>当褐蚁重新踏上峭壁光滑的黑色表面后，它对槽的整体形状有了一个印象：“1”。</strong>…</p>
<p>很快，<strong>它遇到了另一道沟槽</strong>，它很留恋沟槽那粗糙的凹面，在上面爬行感觉很好，同时槽面的颜色也让它想起了蚁后周围的蚁卵。它不惜向下走回头路，沿着槽爬了一趟。这道槽的形状要复杂些，很弯曲，转了一个完整的圈后再向下延伸一段，让它想起在对气味信息的搜寻后终于找到了回家的路的过程，<strong>它在自己的神经网络中建立起了它的形状：“9”。</strong>…</p>
<p>褐蚁继续沿着与地面平行的方向爬，<strong>进入了第三道沟槽</strong>，<strong>它是一个近似于直角的转弯，是这样的：“7”。</strong>它不喜欢这形状，平时，这种不平滑的、突然的转向，往往意味着危险和战斗。…</p>
<p>孤峰上的褐蚁本来想转向向上攀登，<strong>但发现前面还有一道凹槽，同在“7”之前爬过的那个它喜欢的形状“9”一模一样，它就再横行过去，爬了一遍这个“9”。它觉得这个形状比“7”和“1”好，好在哪里当然说不清，这是美感的原始单细胞态；</strong>刚才爬过“9”时的那种模糊的愉悦感再次加强了，这是幸福的原始单细胞态。但这两种精神的单细胞没有进化的机会，现在同一亿年前一样，同一亿年后也一样。</p>
<p>——《三体II 黑暗森林》，刘慈欣 著</p>
</blockquote>
<h2 id="参考文献">参考文献</h2>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p><a href="http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/" target="_blank" rel="external">The Curse of Dimensionality in classification</a>, 中文翻译：<a href="https://zhuanlan.zhihu.com/p/27488363" target="_blank" rel="external">维度灾难</a><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Maaten, L. V. D., &amp; Hinton, G. (2008). Visualizing data using t-SNE. <em>Journal of Machine Learning Research</em>, <em>9</em>(Nov), 2579-2605. <a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" target="_blank" rel="external">[pdf]</a><a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Maaten, L. V. D., &amp; Hinton, G. (2008). Visualizing data using t-SNE. <em>Journal of Machine Learning Research</em>, <em>9</em>(Nov), 2579-2605. <a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" target="_blank" rel="external">[pdf]</a><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Maaten, L. V. D., &amp; Hinton, G. (2008). Visualizing data using t-SNE. <em>Journal of Machine Learning Research</em>, <em>9</em>(Nov), 2579-2605. <a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" target="_blank" rel="external">[pdf]</a><a href="#fnref4">↩</a></p></li>
<li id="fn5"><p><a href="https://www.zhihu.com/question/41106133/answer/154709827" target="_blank" rel="external">有哪些关于流形学习（manifold learning）的好的资料或者课程？</a> - 知乎<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>周志华. 机器学习. 第10章.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Hinton, G. E., &amp; Roweis, S. T. (2003). Stochastic neighbor embedding. In <em>Advances in neural information processing systems</em> (pp. 857-864). <a href="http://papers.nips.cc/paper/2276-stochastic-neighbor-embedding.pdf" target="_blank" rel="external">[pdf]</a><a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Maaten, L. V. D., &amp; Hinton, G. (2008). Visualizing data using t-SNE. <em>Journal of Machine Learning Research</em>, <em>9</em>(Nov), 2579-2605. <a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" target="_blank" rel="external">[pdf]</a><a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>Maaten, L. V. D., &amp; Hinton, G. (2008). Visualizing data using t-SNE. <em>Journal of Machine Learning Research</em>, <em>9</em>(Nov), 2579-2605. <a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" target="_blank" rel="external">[pdf]</a><a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>Cook, J., Sutskever, I., Mnih, A., &amp; Hinton, G. (2007, March). Visualizing similarity data with a mixture of maps. In Artificial Intelligence and Statistics (pp. 67-74). <a href="http://proceedings.mlr.press/v2/cook07a/cook07a.pdf" target="_blank" rel="external">[pdf]</a><a href="#fnref10">↩</a></p></li>
<li id="fn11"><p><a href="http://www.datakit.cn/blog/2017/02/05/t_sne_full.html" target="_blank" rel="external">t-SNE完整笔记</a><a href="#fnref11">↩</a></p></li>
<li id="fn12"><p>Maaten, L. V. D., &amp; Hinton, G. (2008). Visualizing data using t-SNE. <em>Journal of Machine Learning Research</em>, <em>9</em>(Nov), 2579-2605. <a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" target="_blank" rel="external">[pdf]</a><a href="#fnref12">↩</a></p></li>
<li id="fn13"><p>Hinton, G. E., &amp; Roweis, S. T. (2003). Stochastic neighbor embedding. In <em>Advances in neural information processing systems</em> (pp. 857-864). <a href="http://papers.nips.cc/paper/2276-stochastic-neighbor-embedding.pdf" target="_blank" rel="external">[pdf]</a><a href="#fnref13">↩</a></p></li>
<li id="fn14"><p>Hinton, G. E., &amp; Roweis, S. T. (2003). Stochastic neighbor embedding. In <em>Advances in neural information processing systems</em> (pp. 857-864). <a href="http://papers.nips.cc/paper/2276-stochastic-neighbor-embedding.pdf" target="_blank" rel="external">[pdf]</a><a href="#fnref14">↩</a></p></li>
<li id="fn15"><p><a href="https://towardsdatascience.com/reducing-dimensionality-from-dimensionality-reduction-techniques-f658aec24dfe" target="_blank" rel="external">Reducing Dimensionality from Dimensionality Reduction Techniques</a> - medium, 中文翻译：<a href="https://zhuanlan.zhihu.com/p/27935339" target="_blank" rel="external">基于TensorFlow理解三大降维技术：PCA、t-SNE 和自编码器</a> - 机器之心<a href="#fnref15">↩</a></p></li>
<li id="fn16"><p>Van Der Maaten, L. (2014). Accelerating t-SNE using tree-based algorithms. <em>Journal of machine learning research</em>, <em>15</em>(1), 3221-3245. <a href="http://www.jmlr.org/papers/volume15/vandermaaten14a/vandermaaten14a.pdf" target="_blank" rel="external">[pdf]</a><a href="#fnref16">↩</a></p></li>
<li id="fn17"><p><a href="https://towardsdatascience.com/reducing-dimensionality-from-dimensionality-reduction-techniques-f658aec24dfe" target="_blank" rel="external">Reducing Dimensionality from Dimensionality Reduction Techniques</a> - medium, 中文翻译：<a href="https://zhuanlan.zhihu.com/p/27935339" target="_blank" rel="external">基于TensorFlow理解三大降维技术：PCA、t-SNE 和自编码器</a> - 机器之心<a href="#fnref17">↩</a></p></li>
<li id="fn18"><p>Maaten, L. V. D., &amp; Hinton, G. (2008). Visualizing data using t-SNE. <em>Journal of Machine Learning Research</em>, <em>9</em>(Nov), 2579-2605. <a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" target="_blank" rel="external">[pdf]</a><a href="#fnref18">↩</a></p></li>
<li id="fn19"><p>Wattenberg, M., Viégas, F., &amp; Johnson, I. (2016). How to Use t-SNE Effectively. <em>Distill</em>, <em>1</em>(10), e2. <a href="https://distill.pub/2016/misread-tsne/" target="_blank" rel="external">[html]</a><a href="#fnref19">↩</a></p></li>
<li id="fn20"><p>Wattenberg, M., Viégas, F., &amp; Johnson, I. (2016). How to Use t-SNE Effectively. <em>Distill</em>, <em>1</em>(10), e2. <a href="https://distill.pub/2016/misread-tsne/" target="_blank" rel="external">[html]</a><a href="#fnref20">↩</a></p></li>
<li id="fn21"><p>Wattenberg, M., Viégas, F., &amp; Johnson, I. (2016). How to Use t-SNE Effectively. <em>Distill</em>, <em>1</em>(10), e2. <a href="https://distill.pub/2016/misread-tsne/" target="_blank" rel="external">[html]</a><a href="#fnref21">↩</a></p></li>
</ol>
</div>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/t-SNE/" rel="tag"># t-SNE</a>
          
            <a href="/tags/降维/" rel="tag"># 降维</a>
          
            <a href="/tags/流形学习/" rel="tag"># 流形学习</a>
          
            <a href="/tags/Manifold/" rel="tag"># Manifold</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/10/23/hmm-pos-tagger/" rel="next" title="基于HMM模型的词性标注器Python实现">
                <i class="fa fa-chevron-left"></i> 基于HMM模型的词性标注器Python实现
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/12/01/paper-note-t-sne/" rel="prev" title="论文笔记：Visualizing data using t-SNE">
                论文笔记：Visualizing data using t-SNE <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          
            <p class="site-author-name" itemprop="name">Dongyao Hu</p>
            <p class="site-description motion-element" itemprop="description">You Can Advance!</p>
        </div>

        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives/">
            
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#说明"><span class="nav-number">1.</span> <span class="nav-text">说明</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基础篇"><span class="nav-number">2.</span> <span class="nav-text">基础篇</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#认识高维空间维数灾难"><span class="nav-number">2.1.</span> <span class="nav-text">认识高维空间：维数灾难</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#降维"><span class="nav-number">2.2.</span> <span class="nav-text">降维</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#流形学习"><span class="nav-number">2.3.</span> <span class="nav-text">流形学习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#学术篇"><span class="nav-number">3.</span> <span class="nav-text">学术篇</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#sne"><span class="nav-number">3.1.</span> <span class="nav-text">SNE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#t-sne"><span class="nav-number">3.2.</span> <span class="nav-text">t-SNE</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#工程篇"><span class="nav-number">4.</span> <span class="nav-text">工程篇</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#python库sklearn.manifold"><span class="nav-number">4.1.</span> <span class="nav-text">Python库：sklearn.manifold</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#困惑度"><span class="nav-number">4.2.</span> <span class="nav-text">困惑度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#可视化"><span class="nav-number">4.3.</span> <span class="nav-text">可视化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#t-sne优点"><span class="nav-number">4.4.</span> <span class="nav-text">t-SNE优点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#t-sne缺点"><span class="nav-number">4.5.</span> <span class="nav-text">t-SNE缺点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#尾声"><span class="nav-number">5.</span> <span class="nav-text">尾声</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献"><span class="nav-number">6.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Dongyao Hu</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">主题 &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.2</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  








  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("g6tLhjP8k6Y8FQpuyHG3p7Ro-gzGzoHsz", "5Ji54e8dq5KiHiFrMD3mldo2");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
