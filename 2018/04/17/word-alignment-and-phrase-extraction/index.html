<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="machine translation,ibm model 1,机器翻译," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="本学习报告是作为2018年春季学期《机器翻译》课程的部分笔记和实验报告。参考书为 Philipp Koehn 的 Statistical Machine Translation。完整代码见于我的GitHub Repo。  说明 其中实验所使用的运行环境如下：  操作系统：Linux Python版本：3.6 可选：csvkit（pip3 install csvkit）  基于词的翻译模型 简介">
<meta name="keywords" content="machine translation,ibm model 1,机器翻译">
<meta property="og:type" content="article">
<meta property="og:title" content="基于IBM Model 1的词对齐与短语抽取Python实现">
<meta property="og:url" content="http://yoursite.com/2018/04/17/word-alignment-and-phrase-extraction/index.html">
<meta property="og:site_name" content="胡东瑶的小屋">
<meta property="og:description" content="本学习报告是作为2018年春季学期《机器翻译》课程的部分笔记和实验报告。参考书为 Philipp Koehn 的 Statistical Machine Translation。完整代码见于我的GitHub Repo。  说明 其中实验所使用的运行环境如下：  操作系统：Linux Python版本：3.6 可选：csvkit（pip3 install csvkit）  基于词的翻译模型 简介">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-04-17T04:25:30.581Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="基于IBM Model 1的词对齐与短语抽取Python实现">
<meta name="twitter:description" content="本学习报告是作为2018年春季学期《机器翻译》课程的部分笔记和实验报告。参考书为 Philipp Koehn 的 Statistical Machine Translation。完整代码见于我的GitHub Repo。  说明 其中实验所使用的运行环境如下：  操作系统：Linux Python版本：3.6 可选：csvkit（pip3 install csvkit）  基于词的翻译模型 简介">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/04/17/word-alignment-and-phrase-extraction/"/>





  <title>基于IBM Model 1的词对齐与短语抽取Python实现 | 胡东瑶的小屋</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">胡东瑶的小屋</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">You Can Advance!</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/17/word-alignment-and-phrase-extraction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dongyao Hu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="胡东瑶的小屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">基于IBM Model 1的词对齐与短语抽取Python实现</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-17T11:37:53+08:00">
                2018-04-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2018/04/17/word-alignment-and-phrase-extraction/" class="leancloud_visitors" data-flag-title="基于IBM Model 1的词对齐与短语抽取Python实现">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <hr>
<p>本学习报告是作为2018年春季学期《机器翻译》课程的部分笔记和实验报告。参考书为 Philipp Koehn 的 Statistical Machine Translation。完整代码见于我的<a href="https://github.com/psubnwell/hit-mt-2018" target="_blank" rel="external">GitHub Repo</a>。</p>
<hr>
<h1 id="说明">说明</h1>
<p>其中实验所使用的运行环境如下：</p>
<ul>
<li>操作系统：Linux</li>
<li>Python版本：3.6</li>
<li>可选：<code>csvkit</code>（<code>pip3 install csvkit</code>）</li>
</ul>
<h1 id="基于词的翻译模型">基于词的翻译模型</h1>
<h2 id="简介">简介</h2>
<p>基于词的翻译模型起源于上世纪IBM关于统计机器翻译的原创性工作，教材主要介绍的是IBM Model 1模型。该模型能够从大量句对齐的语料中自动实现词对齐。</p>
<p>显然这个任务中，我们即不知道英文词和外文词的对齐方式，也不知道他们两两之间的对齐概率。虽然对齐方式和对齐概率我们都不知道，但是如果我知道其中一个，问题就解决了：知道对齐方式，直接得到答案；知道对齐概率，则通过统计可以得到不同对齐方式的概率，取最大概率的对齐方式即可（极大似然估计）。</p>
<p>我们称“对齐”在这个任务中是隐变量，而解决包含隐变量的训练算法是期望最大算法（EM算法）。EM算法的工作流程如下：</p>
<ol style="list-style-type: decimal">
<li>初始化模型，通常从均匀分布开始。</li>
<li>将模型应用于数据（求期望步骤）。</li>
<li>从数据中学习模型（最大化步骤）。</li>
<li>重复迭代步骤2和3直至收敛。</li>
</ol>
<p>详细的推导详见教材第4章。</p>
<h2 id="词对齐ibm-model-1实验">词对齐（IBM Model 1）实验</h2>
<h3 id="代码解释">代码解释</h3>
<p>本小节我们基于Python使用EM算法实现一个IBM Model 1模型，算法的伪代码位于教材图4.3。</p>
<p>由于使用EM算法，实验需要迭代多轮，直至轮数达到预设值或者误差小于设定阈值。每一轮的训练函数如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_iter</span><span class="params">(f_sents, e_sents, f_vocab, e_vocab, t_prev)</span>:</span></div><div class="line">    t = deepcopy(t_prev)</div><div class="line"></div><div class="line">    <span class="comment"># Initialize count(e|f) and total(f)</span></div><div class="line">    count = &#123;e: &#123;f: <span class="number">0</span> <span class="keyword">for</span> f <span class="keyword">in</span> f_vocab&#125;</div><div class="line">             <span class="keyword">for</span> e <span class="keyword">in</span> e_vocab&#125;</div><div class="line">    total = &#123;f: <span class="number">0</span> <span class="keyword">for</span> f <span class="keyword">in</span> f_vocab&#125;</div><div class="line"></div><div class="line">    <span class="keyword">for</span> f_sent, e_sent <span class="keyword">in</span> zip(f_sents, e_sents):</div><div class="line">        fs = f_sent.split()</div><div class="line">        es = e_sent.split()</div><div class="line">        <span class="comment"># In fact s_total is a float,</span></div><div class="line">        <span class="comment"># we make it a dict for better readability</span></div><div class="line">        s_total = &#123;e: <span class="number">0</span> <span class="keyword">for</span> e <span class="keyword">in</span> e_vocab&#125;</div><div class="line"></div><div class="line">        <span class="comment"># Compute normalization</span></div><div class="line">        <span class="comment"># Eq 4.13 denominator part</span></div><div class="line">        <span class="keyword">for</span> e <span class="keyword">in</span> es:</div><div class="line">            s_total[e] = <span class="number">0</span></div><div class="line">            <span class="keyword">for</span> f <span class="keyword">in</span> fs:</div><div class="line">                s_total[e] += t[e][f]</div><div class="line"></div><div class="line">        <span class="comment"># Collect counts</span></div><div class="line">        <span class="keyword">for</span> e <span class="keyword">in</span> es:</div><div class="line">            <span class="keyword">for</span> f <span class="keyword">in</span> fs:</div><div class="line">                <span class="comment"># Eq 4.14 numerator part</span></div><div class="line">                count[e][f] += t[e][f] / s_total[e]</div><div class="line">                <span class="comment"># Eq 4.14 denominator part</span></div><div class="line">                total[f] += t[e][f] / s_total[e]</div><div class="line"></div><div class="line">    <span class="comment"># Estimate probabilities</span></div><div class="line">    <span class="comment"># Eq 4.14</span></div><div class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> t.keys():</div><div class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> t[e].keys():</div><div class="line">            t[e][f] = count[e][f] / total[f]</div><div class="line"></div><div class="line">    <span class="keyword">return</span> t</div></pre></td></tr></table></figure>
<p>代码中比较重要的地方标注了教材对应的公式，方便对照查阅。</p>
<p>总训练函数<code>train</code>在每一轮训练中调用以上<code>train_iter</code>函数，代码如下（结果输出部分省略）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(f_corpus, e_corpus, epsilon, iter_num, save_dir, save_iteration=False, save_alignment=True)</span>:</span></div><div class="line">    f_sents = load_corpus(f_corpus)</div><div class="line">    e_sents = load_corpus(e_corpus)</div><div class="line">    f_vocab = build_vocab(f_corpus)</div><div class="line">    e_vocab = build_vocab(e_corpus)</div><div class="line"></div><div class="line">    t_prev = init_t(f_sents, e_sents, e_vocab)</div><div class="line"></div><div class="line">    converged = <span class="keyword">False</span></div><div class="line">    i = <span class="number">0</span></div><div class="line"></div><div class="line">    <span class="keyword">while</span> <span class="keyword">not</span> converged <span class="keyword">and</span> i &lt; iter_num:</div><div class="line">        t = train_iter(f_sents, e_sents, f_vocab, e_vocab, t_prev)</div><div class="line">        converged, delta = is_converged(t_prev, t, epsilon)</div><div class="line">        i += <span class="number">1</span></div><div class="line">        t_prev = t</div><div class="line">    <span class="keyword">return</span> t</div></pre></td></tr></table></figure>
<p>程序使用<code>argparse</code>来输入参数，需要输入的参数有：</p>
<ul>
<li><code>--f-corpus</code>：外语语料路径，每行一句（中文语料需分好词）。</li>
<li><code>--e-corpus</code>：英语语料路径，每行一句，须与外语语料句对齐。</li>
<li><code>--save-dir</code>：结果保存路径。</li>
<li><code>--epsilon</code>：设定误差阈值。（默认值=1e3）</li>
<li><code>--iter-num</code>：设定训练轮数。（默认值=10）</li>
<li><code>--save-iteration</code>/<code>--no-save-iteration</code>：是否保存每一轮迭代后的词翻译概率（语料较大勿用，内存容易溢出，仅作为演示用）</li>
<li><code>--save-alignment</code>/<code>--no-save-alignment</code>：是否保存词对齐的结果。</li>
</ul>
<h3 id="小语料运行演示">小语料运行演示</h3>
<p>我们可以先使用教材上的例句来进行实验，这时输入语料为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">$ cat example.de</div><div class="line">das haus</div><div class="line">das buch</div><div class="line">ein buch</div><div class="line"></div><div class="line">$ cat example.en</div><div class="line">the house</div><div class="line">the book</div><div class="line">a book</div></pre></td></tr></table></figure>
<p>在终端按如下参数输入命令即可开始训练，输出的日志会记载每一轮的时间和误差：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">$ python ibm_model_1.py --f-corpus example.de --e-corpus example.en --iter-num 10 --save-iteration --save-alignment</div><div class="line">2018-04-16 18:51:45  Start!</div><div class="line">2018-04-16 18:51:45  Iteration 1 finished! Delta = 0.6123724356957945.</div><div class="line">2018-04-16 18:51:45    Iteration information saved!</div><div class="line">2018-04-16 18:51:45    Alignment result saved!</div><div class="line">2018-04-16 18:51:45  Iteration 2 finished! Delta = 0.27603131567314654.</div><div class="line">2018-04-16 18:51:45    Iteration information saved!</div><div class="line">2018-04-16 18:51:45    Alignment result saved!</div><div class="line">...</div><div class="line">2018-04-16 18:51:45  Iteration 10 finished! Delta = 0.030043132479938874.</div><div class="line">2018-04-16 18:51:45    Iteration information saved!</div><div class="line">2018-04-16 18:51:45    Alignment result saved!</div><div class="line">2018-04-16 18:51:45  Finished!</div></pre></td></tr></table></figure>
<p>输出的结果中的<code>iterations.csv</code>文件记录每一个词对齐的翻译概率，可以看到和教材图4.4一致：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">$ csvlook iterations.csv</div><div class="line">| e     | f    | 0 it. | 1 it. |  2 it. |  3 it. |  4 it. |  5 it. |  6 it. | … |</div><div class="line">| ----- | ---- | ----- | ----- | ------ | ------ | ------ | ------ | ------ | - |</div><div class="line">| the   | das  |  0.25 |  0.50 | 0.636… | 0.748… | 0.834… | 0.896… | 0.937… | … |</div><div class="line">| the   | haus |  0.25 |  0.50 | 0.429… | 0.347… | 0.276… | 0.218… | 0.174… | … |</div><div class="line">| the   | buch |  0.25 |  0.25 | 0.182… | 0.121… | 0.075… | 0.044… | 0.025… | … |</div><div class="line">| a     | ein  |  0.25 |  0.50 | 0.571… | 0.653… | 0.724… | 0.782… | 0.826… | … |</div><div class="line">| a     | buch |  0.25 |  0.25 | 0.182… | 0.131… | 0.090… | 0.060… | 0.038… | … |</div><div class="line">| book  | das  |  0.25 |  0.25 | 0.182… | 0.121… | 0.075… | 0.044… | 0.025… | … |</div><div class="line">| book  | buch |  0.25 |  0.50 | 0.636… | 0.748… | 0.834… | 0.896… | 0.937… | … |</div><div class="line">| book  | ein  |  0.25 |  0.50 | 0.429… | 0.347… | 0.276… | 0.218… | 0.174… | … |</div><div class="line">| house | das  |  0.25 |  0.25 | 0.182… | 0.131… | 0.090… | 0.060… | 0.038… | … |</div><div class="line">| house | haus |  0.25 |  0.50 | 0.571… | 0.653… | 0.724… | 0.782… | 0.826… | … |</div></pre></td></tr></table></figure>
<p>输出结果中的<code>alignment.txt</code>文件记录了每一个英文词对应概率最大的外文词：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ cat output/example/alignment.txt </div><div class="line">the		das		0.9629780468299598</div><div class="line">book	buch	0.9629780468299598</div><div class="line">a		ein		0.8592290797833062</div><div class="line">house	haus	0.8592290797833062</div></pre></td></tr></table></figure>
<p>以上试运行表明程序设计正确，接下来我们将程序运行于较大的语料上。</p>
<h3 id="大语料运行演示">大语料运行演示</h3>
<p>我们使用的FBIS语料为中英对齐语料，数量为10k，内容如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">$ head -n 3 fbis.zh.10k </div><div class="line">伊犁 大规模 开展 “ 面 对 面 ” 宣讲 活动</div><div class="line">新华社 乌鲁木齐 2 月 1 日 电 ( 记者 樊英利 、 丁建刚 、 李秀芩 ) 为 促进 民族 团结 , 维护 社会 安定 , 近年 来 新疆 伊犁 创造 性地 开展 了 “ 面 对 面 ” 宣讲 活动 , 让 各 族 群众 听到 了 党 和 政府 的 声音 , 受到 热烈 欢迎 。</div><div class="line">地处 西北 边陲 的 伊犁 是 我国 对外 开放 的 重要 窗口 , 改革 开放 以来 , 伊犁 经济 获得 长足 发展 , 人民 生活 水平 迅速 提高 。</div><div class="line"></div><div class="line">$ head -n 3 fbis.en.10k </div><div class="line"><span class="string">" Yili Launches Large-Scale ' Face-to-face ' Propaganda Activity "</span></div><div class="line">Urumqi , 1 Feb ( Xinhua ) -- Over the past few years , <span class="keyword">in</span> order to promote nationality solidarity and safeguard social stability , Xinjiang <span class="string">'s Yili has launched in a creative way a " face-to-face " propaganda activity to let the people of all nationalities hear the voice of the party and government , and the activity has been warmly welcomed .</span></div><div class="line"><span class="string">Located in the country '</span>s northwestern border , Yili has served as an important window during the country <span class="string">'s opening up to the outside world . Since reform and opening up , Yili has developed the economy by a large margin and rapidly improved the people '</span>s livelihood .</div></pre></td></tr></table></figure>
<p>在终端使用如下参数训练：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">$ python ibm_model_1.py --f-corpus fbis.zh.10k --e-corpus fbis.en.10k --iter-num 10 --save-alignment</div><div class="line">2018-04-16 10:43:08  Start!</div><div class="line">2018-04-16 10:44:39  Iteration 1 finished! Delta = 23.41954195051294.</div><div class="line">2018-04-16 10:45:10    Alignment result saved!</div><div class="line">2018-04-16 10:46:38  Iteration 2 finished! Delta = 14.01728672063726.</div><div class="line">2018-04-16 10:47:10    Alignment result saved!</div><div class="line">...</div><div class="line">2018-04-16 11:01:38  Iteration 10 finished! Delta = 1.5178054587297218.</div><div class="line">2018-04-16 11:02:08    Alignment result saved!</div><div class="line">2018-04-16 11:02:09  Finished!</div></pre></td></tr></table></figure>
<p>查看输出的<code>alignment.txt</code>可见：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">$ less alignment.txt</div><div class="line">introduction    引言    1.0</div><div class="line">military        军事    0.9304993049061553</div><div class="line">or      		或      0.9282035832570313</div><div class="line">kosovo  		科索沃  0.9240566375315791</div><div class="line">other   		其他    0.920736615880717</div><div class="line">15      		十五日  0.8979442872284269</div><div class="line">mobile  		移动    0.8891564322429747</div><div class="line">information     信息    0.8889118851814501</div><div class="line">spokesman       发言人  0.8861872025346202</div><div class="line">advanced        先进    0.881666924721701</div><div class="line">taiwan  		台湾    0.8799311621606325</div><div class="line">shenzhen        深圳    0.8628715295934547</div><div class="line">grain   		粮食    0.86138574336857</div><div class="line">power   		权力    0.86018486222242</div><div class="line">coal    		煤炭    0.8597328766954059</div><div class="line"><span class="string">"       		」      0.8563750182248889</span></div><div class="line"><span class="string">new     		新      0.8513703789669643</span></div><div class="line"><span class="string">...</span></div></pre></td></tr></table></figure>
<p>当然为了下一章的短语抽取实验，我们还需要记录每个英文词所有的对齐候选词以及翻译概率，这个文件以json格式输出存储，内容较杂乱，这里不再展示。</p>
<h1 id="基于短语的翻译模型">基于短语的翻译模型</h1>
<h2 id="简介-1">简介</h2>
<p>基于词的翻译模型并不符合语言学，可以使用短语来作为基本的翻译单元。显然，基于短语的翻译系统性能取决于从基于词的翻译模型中得到的短语翻译表。得到词对齐后，每输入一个句对，可以将其表示为教材图5.3所示矩阵，使用黑色方块表示词的对齐。我们的任务是从这个含有黑色方块的矩阵中，用灰色矩形框出满足一致性（“一致性”从视觉上很容易理解，详见图5.4；其形式化定义见公式（5.3））的一个或者多个黑色方块。</p>
<p>算法思想比较简单，即使用两层for循环遍历矩阵，遇到符合的区域就提取其中的短语。但是需要处理一些边角情形，如对空的情况等。</p>
<h2 id="短语抽取实验">短语抽取实验</h2>
<h3 id="代码解释-1">代码解释</h3>
<p>本小节我们使用Python实现一个短语抽取的模型，该模型能根据之前实验得到的词对齐，从大量句对齐的语料中通过实现短语自动抽取（抽取的短语不一定具有语言学意义）。算法的伪代码位于教材图5.5。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">phrase_extraction</span><span class="params">(f_sent, e_sent, A)</span>:</span></div><div class="line">    BP = []</div><div class="line">    <span class="keyword">for</span> e_start <span class="keyword">in</span> range(<span class="number">1</span>, len(e_sent) + <span class="number">1</span>):</div><div class="line">        <span class="keyword">for</span> e_end <span class="keyword">in</span> range(e_start, len(e_sent) + <span class="number">1</span>):</div><div class="line">            <span class="comment"># Find the minimally matching foreign phrase</span></div><div class="line">            f_start, f_end = len(f_sent), <span class="number">0</span></div><div class="line">            <span class="keyword">for</span> (e, f) <span class="keyword">in</span> A:</div><div class="line">                <span class="keyword">if</span> e_start &lt;= e &lt;= e_end:</div><div class="line">                    f_start = min(f, f_start)</div><div class="line">                    f_end = max(f, f_end)</div><div class="line">            BP += extract(f_start, f_end, e_start, e_end, f_sent, e_sent, A)</div><div class="line">    <span class="keyword">return</span> BP</div></pre></td></tr></table></figure>
<p>该函数内双重for循环不断调整着预计抽取短语对的开始、结束下标。每找到一组可行的下标（<code>e_start</code>，<code>e_end</code>，<code>f_start</code>, <code>f_end</code>），就进入第11行使用<code>extract</code>函数进行抽取。例如输入的对齐<code>A=[(1,1), (2,2)]</code>（即教材上的黑格子坐标），则可以进行三次抽取，每次抽取的下标范围为<code>(1,1,1,1)</code>、<code>(1,2,1,2)</code>、<code>(2,2,2,2)</code>（即教材上的灰矩形坐标，由两个顶点确定）。</p>
<p>抽取的函数代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract</span><span class="params">(f_start, f_end, e_start, e_end, f_sent, e_sent, A)</span>:</span></div><div class="line">    <span class="keyword">if</span> f_end == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> []</div><div class="line">    <span class="comment"># Check if alignment points violate consistency</span></div><div class="line">    <span class="keyword">for</span> (e, f) <span class="keyword">in</span> A:</div><div class="line">        <span class="keyword">if</span> (e &lt; e_start <span class="keyword">or</span> e &gt; e_end) <span class="keyword">and</span> f_start &lt;= f &lt;= f_end:</div><div class="line">            <span class="keyword">return</span> []</div><div class="line">    <span class="comment"># Add phrase pairs (incl. additional unaligned f)</span></div><div class="line">    E = []</div><div class="line">    f_s = f_start</div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        f_e = f_end</div><div class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">            e_phrase = <span class="string">' '</span>.join(e_sent[e_start<span class="number">-1</span>: e_end])</div><div class="line">            f_phrase = <span class="string">' '</span>.join(f_sent[f_s<span class="number">-1</span>: f_e])</div><div class="line">            E.append((e_phrase, f_phrase))</div><div class="line">            f_e += <span class="number">1</span></div><div class="line">            <span class="keyword">if</span> <span class="keyword">not</span> is_aligned(A, f_e, f_sent, e_start, e_end):</div><div class="line">                <span class="keyword">break</span></div><div class="line">        f_s -= <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> is_aligned(A, f_s, f_sent, e_start, e_end):</div><div class="line">            <span class="keyword">break</span></div><div class="line">    <span class="keyword">return</span> E</div></pre></td></tr></table></figure>
<p>注意教材上伪代码第4行（对应此代码第6行）缺少条件，这里添加了后半个条件，否则输出将是整个句对。</p>
<p>抽取给定的下标范围的短语后，还要检测其前后有无对空的可能性。<code>is_aligned</code>函数用于检测这种情况：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_aligned</span><span class="params">(A, f_ind, sent, e_start, e_end)</span>:</span></div><div class="line">    f_align = []</div><div class="line">    <span class="keyword">for</span> (e, f) <span class="keyword">in</span> A:</div><div class="line">        <span class="keyword">if</span> f == f_ind:</div><div class="line">            f_align.append(e)</div><div class="line">    <span class="keyword">if</span> f_ind &lt; <span class="number">1</span> <span class="keyword">or</span> f_ind &gt; len(sent):</div><div class="line">        <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">    <span class="keyword">if</span> len(f_align) &gt; <span class="number">0</span> <span class="keyword">and</span> (min(f_align) &lt; e_start <span class="keyword">or</span> max(f_align) &gt; e_end):</div><div class="line">        <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">True</span></div></pre></td></tr></table></figure>
<p>程序使用<code>argparse</code>来输入参数，需要输入的参数有：</p>
<ul>
<li><p><code>--f-corpus</code>：外语语料路径，每行一句（中文语料需分好词）。</p></li>
<li><p><code>--e-corpus</code>：英语语料路径，每行一句，须与外语语料句对齐。</p></li>
<li><p><code>--save-dir</code>：结果保存路径。</p></li>
<li><p><code>--alignment</code>：对齐文件路径，json格式，可由上一个实验自动生成。内容为一个嵌套字典，如下所示：</p></li>
</ul>
<p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&#123;<span class="string">"the"</span>: &#123;<span class="string">"das"</span>: 0.9629780468299598, <span class="string">"haus"</span>: 0.14077092021669385, <span class="string">"buch"</span>: 0.01385591209260682&#125;, </div><div class="line"> <span class="string">"a"</span>: &#123;<span class="string">"ein"</span>: 0.8592290797833062, <span class="string">"buch"</span>: 0.023166041077433423&#125;, </div><div class="line"> <span class="string">"book"</span>: &#123;<span class="string">"das"</span>: 0.013855912092606825, <span class="string">"buch"</span>: 0.9629780468299598, <span class="string">"ein"</span>: 0.14077092021669385&#125;, </div><div class="line"> <span class="string">"house"</span>: &#123;<span class="string">"das"</span>: 0.023166041077433423, <span class="string">"haus"</span>: 0.8592290797833062&#125;&#125;</div></pre></td></tr></table></figure></p>
<h3 id="小语料运行演示-1">小语料运行演示</h3>
<p>我们使用以上程序演示一下教材图5.6的实例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    f_sent = <span class="string">'michael geht davon aus , dass er im haus bleibt'</span>.split()</div><div class="line">    e_sent = <span class="string">'michael assumes that he will stay in the house'</span>.split()</div><div class="line">    A = [(<span class="number">1</span>,<span class="number">1</span>), (<span class="number">2</span>,<span class="number">2</span>), (<span class="number">2</span>,<span class="number">3</span>), (<span class="number">2</span>,<span class="number">4</span>), (<span class="number">3</span>,<span class="number">6</span>), (<span class="number">4</span>,<span class="number">7</span>), (<span class="number">5</span>,<span class="number">10</span>), (<span class="number">6</span>,<span class="number">10</span>), (<span class="number">7</span>,<span class="number">8</span>), (<span class="number">8</span>,<span class="number">9</span>), (<span class="number">9</span>,<span class="number">9</span>)]</div><div class="line"></div><div class="line">    phrases = phrase_extraction(f_sent, e_sent, A)</div><div class="line">    print(phrases)</div><div class="line">    print(<span class="string">'Total &#123;&#125; phrases.'</span>.format(len(phrases)))</div></pre></td></tr></table></figure>
<p>在终端执行后可以得到和教材完全一致的结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">$ python demo.py </div><div class="line">[(<span class="string">'michael'</span>, <span class="string">'michael'</span>), </div><div class="line"> (<span class="string">'michael assumes'</span>, <span class="string">'michael geht davon aus'</span>), </div><div class="line"> (<span class="string">'michael assumes'</span>, <span class="string">'michael geht davon aus ,'</span>), </div><div class="line"> (<span class="string">'michael assumes that'</span>, <span class="string">'michael geht davon aus , dass'</span>), </div><div class="line"> (<span class="string">'michael assumes that he'</span>, <span class="string">'michael geht davon aus , dass er'</span>), </div><div class="line"> (<span class="string">'michael assumes that he will stay in the house'</span>, <span class="string">'michael geht davon aus , dass er im haus bleibt'</span>), </div><div class="line"> (<span class="string">'assumes'</span>, <span class="string">'geht davon aus'</span>), </div><div class="line"> (<span class="string">'assumes'</span>, <span class="string">'geht davon aus ,'</span>), </div><div class="line"> (<span class="string">'assumes that'</span>, <span class="string">'geht davon aus , dass'</span>), </div><div class="line"> (<span class="string">'assumes that he'</span>, <span class="string">'geht davon aus , dass er'</span>), </div><div class="line"> (<span class="string">'assumes that he will stay in the house'</span>, <span class="string">'geht davon aus , dass er im haus bleibt'</span>), </div><div class="line"> (<span class="string">'that'</span>, <span class="string">'dass'</span>), </div><div class="line"> (<span class="string">'that'</span>, <span class="string">', dass'</span>), </div><div class="line"> (<span class="string">'that he'</span>, <span class="string">'dass er'</span>), </div><div class="line"> (<span class="string">'that he'</span>, <span class="string">', dass er'</span>), </div><div class="line"> (<span class="string">'that he will stay in the house'</span>, <span class="string">'dass er im haus bleibt'</span>), </div><div class="line"> (<span class="string">'that he will stay in the house'</span>, <span class="string">', dass er im haus bleibt'</span>), </div><div class="line"> (<span class="string">'he'</span>, <span class="string">'er'</span>), </div><div class="line"> (<span class="string">'he will stay in the house'</span>, <span class="string">'er im haus bleibt'</span>), </div><div class="line"> (<span class="string">'will stay'</span>, <span class="string">'bleibt'</span>), </div><div class="line"> (<span class="string">'will stay in the house'</span>, <span class="string">'im haus bleibt'</span>), </div><div class="line"> (<span class="string">'in'</span>, <span class="string">'im'</span>), </div><div class="line"> (<span class="string">'in the house'</span>, <span class="string">'im haus'</span>), </div><div class="line"> (<span class="string">'the house'</span>, <span class="string">'haus'</span>)]</div><div class="line">Total 24 phrases.</div></pre></td></tr></table></figure>
<h3 id="大语料运行演示-1">大语料运行演示</h3>
<p>仍旧使用的FBIS语料为中英对齐语料，在终端以如下参数执行程序：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ python phrase_extraction.py --f-corpus fbis.zh.10k --e-corpus fbis.en.10k --alignment alignment_all.json</div></pre></td></tr></table></figure>
<p>抽取的短语如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">$ less phrases.txt</div><div class="line"><span class="string">"  --  “</span></div><div class="line"><span class="string">"</span>  --  开展 “</div><div class="line"><span class="string">" yili launches large-scale ' face-to-face  --  伊犁 大规模 开展 “ 面</span></div><div class="line"><span class="string">"</span> yili launches large-scale <span class="string">' face-to-face  --  伊犁 大规模 开展 “ 面 对</span></div><div class="line"><span class="string">" yili launches large-scale '</span> face-to-face  --  伊犁 大规模 开展 “ 面 对 面</div><div class="line"><span class="string">" yili launches large-scale ' face-to-face  --  伊犁 大规模 开展 “ 面 对 面 ”</span></div><div class="line"><span class="string">...</span></div><div class="line"><span class="string">yili  --  伊犁</span></div><div class="line"><span class="string">large-scale  --  大规模</span></div><div class="line"><span class="string">large-scale  --  大规模 开展</span></div><div class="line"><span class="string">' propaganda activity  --  宣讲</span></div><div class="line"><span class="string">' propaganda activity  --  宣讲 活动</span></div></pre></td></tr></table></figure>
<p>结果基本正确，但由于部分词没有相应的对齐，以及没有对抽取行为做限制，仍有较多瑕疵。后续可以通过训练更好的词对齐（如正反训练一遍做并集）、对抽取短语的长度做限制等，可以提升抽取结果的质量。</p>
<h1 id="结语神经机器翻译与其他">结语：神经机器翻译与其他</h1>
<p>机器翻译从形式上来说，是序列到序列的任务，但是和序列标注任务（如词性标注）不同的是，大多属情况下，源端序列和目标端序列长度不一致。因此序列标注任务中使用的HMM、CRF等模型不再适用，需要有其他的翻译模型。</p>
<p>在机器翻译的课堂上，除了传统的统计机器翻译（SMT）外，我们也涉猎了若干前沿的神经机器翻译（NMT）模型。神经机器翻译基于深度的神经网络模型，比如CNN和RNN。RNN擅长处理时序模型，可以从输入端随着时序喂入一个分词的句子（以词向量形式），RNN能够在内部维持一个隐状态参数矩阵，用于将上一个时刻的输出，通过该参数矩阵传入下一个时刻，以此解决长程依赖。</p>
<p>为了解决RNN在长距离上梯度传递的消失和爆炸，可以引入LSTM。LSTM在内部使用三个具有可学习参数的门控来决定哪些信息该输入、遗忘、输出，从而解决梯度消失和爆炸的问题。</p>
<p>神经机器翻译模型一般采用seq2seq模型，seq2seq模型采用encoder-decoder的结构，这里的encoder和decoder可以是CNN也可以是RNN。encoder将输入的句子转化（编码）为一个中间状态向量，decoder则通过此中间状态向量和前面已经翻译好的词汇解码出下一个翻译词汇。seq2seq模型还可以搭配attention机制，可以得到更优秀的、更具有语言学意义的翻译模型。</p>
<p>尽管NMT全面胜出SMT，但NMT参数过多，运行时间过长的缺点也不容小觑。可以使用简单但同样强大的结构来提速，如FAIR提出的纯CNN翻译模型；也有通过改进梯度传导过程中类似“剪枝”的手段来避免无用部分的梯度传导等根本性的改进。NMT有比较大的潜力，后续将尝试研究和实现。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/machine-translation/" rel="tag"># machine translation</a>
          
            <a href="/tags/ibm-model-1/" rel="tag"># ibm model 1</a>
          
            <a href="/tags/机器翻译/" rel="tag"># 机器翻译</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/01/18/apriori-and-fp-growth/" rel="next" title="Apriori与FP-Growth算法的实现与比较">
                <i class="fa fa-chevron-left"></i> Apriori与FP-Growth算法的实现与比较
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          
            <p class="site-author-name" itemprop="name">Dongyao Hu</p>
            <p class="site-description motion-element" itemprop="description">You Can Advance!</p>
        </div>

        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives/">
            
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#说明"><span class="nav-number">1.</span> <span class="nav-text">说明</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基于词的翻译模型"><span class="nav-number">2.</span> <span class="nav-text">基于词的翻译模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#简介"><span class="nav-number">2.1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#词对齐ibm-model-1实验"><span class="nav-number">2.2.</span> <span class="nav-text">词对齐（IBM Model 1）实验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#代码解释"><span class="nav-number">2.2.1.</span> <span class="nav-text">代码解释</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#小语料运行演示"><span class="nav-number">2.2.2.</span> <span class="nav-text">小语料运行演示</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#大语料运行演示"><span class="nav-number">2.2.3.</span> <span class="nav-text">大语料运行演示</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基于短语的翻译模型"><span class="nav-number">3.</span> <span class="nav-text">基于短语的翻译模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#简介-1"><span class="nav-number">3.1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#短语抽取实验"><span class="nav-number">3.2.</span> <span class="nav-text">短语抽取实验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#代码解释-1"><span class="nav-number">3.2.1.</span> <span class="nav-text">代码解释</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#小语料运行演示-1"><span class="nav-number">3.2.2.</span> <span class="nav-text">小语料运行演示</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#大语料运行演示-1"><span class="nav-number">3.2.3.</span> <span class="nav-text">大语料运行演示</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#结语神经机器翻译与其他"><span class="nav-number">4.</span> <span class="nav-text">结语：神经机器翻译与其他</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Dongyao Hu</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">主题 &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.2</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  








  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("g6tLhjP8k6Y8FQpuyHG3p7Ro-gzGzoHsz", "5Ji54e8dq5KiHiFrMD3mldo2");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
